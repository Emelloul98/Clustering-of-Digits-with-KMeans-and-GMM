# Clustering with GMM and KMeans

This project implements two unsupervised machine learning algorithms: Gaussian Mixture Model (GMM) and KMeans clustering. The goal of the project is to cluster a dataset and compare the performance of both algorithms in terms of clustering accuracy and visualization.

---

**Description:**

The project focuses on clustering a dataset using two popular clustering techniques: KMeans and GMM. The Gaussian Mixture Model (GMM) is a probabilistic model that assumes the data points are generated from a mixture of several Gaussian distributions, while KMeans is a centroid-based algorithm that assigns each data point to the nearest cluster. The performance of these algorithms is evaluated based on clustering accuracy, inertia, and visualization.

---

**Project Structure:**

1. **Data Preprocessing:**
   - The dataset `data.csv` is preprocessed by scaling the features using `StandardScaler` to normalize the data before clustering.
   
2. **KMeans Clustering:**
   - KMeans is applied to the dataset, and the optimal number of clusters is determined using the elbow method.
   - The model is evaluated based on inertia (sum of squared distances to the nearest centroid) and silhouette score.

3. **Gaussian Mixture Model (GMM) Clustering:**
   - GMM is applied to the dataset to model the data using a mixture of Gaussian distributions.
   - The model is evaluated based on log-likelihood and the Bayesian Information Criterion (BIC) to determine the optimal number of clusters.
   
4. **Visualization:**
   - The clusters generated by both KMeans and GMM are visualized using scatter plots, allowing a comparison of the clusters identified by each algorithm.
   
---

**Usage:**

1. **Data Preprocessing:**
   - The dataset is loaded and scaled for optimal clustering performance.

   ```python
   from sklearn.preprocessing import StandardScaler
   df = pd.read_csv('data.csv')
   scaler = StandardScaler()
   X_scaled = scaler.fit_transform(df)
   ```

2. **KMeans Clustering:**
   - Apply KMeans to cluster the dataset and visualize the clusters:

   ```python
   from sklearn.cluster import KMeans
   kmeans = KMeans(n_clusters=3)
   kmeans.fit(X_scaled)
   y_kmeans = kmeans.predict(X_scaled)
   ```

3. **GMM Clustering:**
   - Apply GMM to cluster the dataset and evaluate the results:

   ```python
   from sklearn.mixture import GaussianMixture
   gmm = GaussianMixture(n_components=3)
   gmm.fit(X_scaled)
   y_gmm = gmm.predict(X_scaled)
   ```

4. **Performance Evaluation:**
   - Compare the performance of KMeans and GMM using silhouette score and BIC:

   ```python
   from sklearn.metrics import silhouette_score
   silhouette_kmeans = silhouette_score(X_scaled, y_kmeans)
   silhouette_gmm = silhouette_score(X_scaled, y_gmm)
   ```

---

**Features:**

- **Data Preprocessing:**
  - Standard scaling for numerical features.
  
- **Clustering Algorithms:**
  - KMeans for centroid-based clustering.
  - GMM for probabilistic Gaussian mixture clustering.
  
- **Performance Evaluation:**
  - Inertia, silhouette score for KMeans evaluation.
  - Log-likelihood, BIC for GMM evaluation.
  
- **Visualization:**
  - Scatter plots of clusters for both KMeans and GMM.
  
---

**Dependencies:**

The project uses the following Python libraries:

- `pandas`
- `numpy`
- `scikit-learn`
- `matplotlib`

To install the required dependencies, use the following command:

```bash
pip install pandas numpy scikit-learn matplotlib
```

---

**Example Results:**

- **KMeans Clustering Visualization:**
  - Scatter plot showing the clusters generated by KMeans.

  ![KMeans Clustering](https://github.com/Emelloul98/Clustering-Project/blob/main/kmeans.png)

- **GMM Clustering Visualization:**
  - Scatter plot showing the clusters generated by GMM.

  ![GMM Clustering](https://github.com/Emelloul98/Clustering-Project/blob/main/gmm.png)

---

This README provides an overview of the clustering project, its structure, usage, and performance evaluation for GMM and KMeans clustering.
